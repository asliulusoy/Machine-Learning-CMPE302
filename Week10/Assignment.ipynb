{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "\n",
    "Build an SVM model using the scikit-learn library. Explore both linear and\n",
    "kernel-based SVMs and examine the effects of different kernel functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### 1. Understanding SVMs:\n",
    "\n",
    "https://github.com/asliulusoy/Machine-Learning-CMPE302/blob/main/Week10/Support_Vector_Machines-Main-Ideas.md\n",
    "\n",
    "### 2. Exploring sckit-learn Documentation:\n",
    "* **C (Regularization parameter)**\n",
    "    - Default: 1.0\n",
    "    - Controls the trade-off between smooth decision boundary and classifying training points correctly. A high value fits to the training data more closely.\n",
    "* **kernel**\n",
    "    - Default: 'rbf'\n",
    "    - Options: 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'\n",
    "    - Specifies the kernel type to be used in the SVM.\n",
    "* **degree**\n",
    "    - Default: 3\n",
    "    - Description: Degree of the polynomial kernel function. Important for polynomial kernels to capture the complexity in the data.\n",
    "* **gamma**\n",
    "    - Default: 'scale'\n",
    "    - Determines the influence of individual training examples. High values closely fit the training dataset, which can cause overfitting.\n",
    "        * if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
    "        * if ‘auto’, uses 1 / n_features\n",
    "        * if float, must be non-negative.\n",
    "* **coef0**\n",
    "    - Default: 0.0\n",
    "    - Independent term in kernel function. Significant in 'poly' and 'sigmoid' kernels.\n",
    "* **shrinking**\n",
    "    - Default: True\n",
    "    - Whether to use the shrinking heuristic to speed up optimization.\n",
    "* **probability**\n",
    "    - Default: False\n",
    "    - Whether to enable probability estimates. This is computationally expensive as it internally uses cross-validation.\n",
    "* **class_weight**\n",
    "    - Default: None\n",
    "    -  Adjusts weights inversely proportional to class frequencies or as specified by the user.\n",
    "\n",
    "### 3. Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. Loading and cleaning the \"iris\" dataset. Determining how to handle missing values if present.\n",
    "* 2. Preparing the data by scaling or normalizing.\n",
    "\n",
    "#### Load & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DATASET\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether there is null or duplicated values or not and handling them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum()) #check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() #check duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates() #drop duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Scaling/Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA SCALING\n",
    "features = df.columns[:-1]\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Building\n",
    "\n",
    "* 1. Start by building and training a linear SVM model.\n",
    "* 2. Then, create kernel-based SVM models using different kernel functions such as RBF, Polynomial, and Sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING DATASET\n",
    "\n",
    "X=df[features]\n",
    "y=df['target']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearSVMmodel=SVC(kernel='linear')\n",
    "linearSVMmodel.fit(X_train, y_train)\n",
    "y_predLinear= linearSVMmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Confusion Matrix Results\n",
      "\n",
      "Accuracy Score:\n",
      "0.9777777777777777\n",
      "\n",
      "Cross Validation Score:\n",
      "[1.         0.85714286 0.9047619  1.         0.95      ]\n",
      "\n",
      "Mean CV Score:\n",
      "0.9423809523809524\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVM Confusion Matrix Results\")\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test,y_predLinear))\n",
    "print(\"\\nCross Validation Score:\")\n",
    "print(cross_val_score(linearSVMmodel, X_train, y_train, cv=5))\n",
    "print(\"\\nMean CV Score:\")\n",
    "print(cross_val_score(linearSVMmodel, X_train, y_train, cv=5).mean()) \n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_predLinear))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_predLinear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Kernel Based SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBF\n",
    "\n",
    "RBFSVMmodel=SVC(kernel='rbf')\n",
    "RBFSVMmodel.fit(X_train, y_train)\n",
    "y_predRBF= RBFSVMmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM Confusion Matrix Results\n",
      "\n",
      "Accuracy Score:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score:\n",
      "[1.         0.80952381 0.9047619  1.         0.95      ]\n",
      "\n",
      "Mean CV Score:\n",
      "0.9328571428571429\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RBF SVM Confusion Matrix Results\")\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test,y_predRBF))\n",
    "print(\"\\nCross Validation Score:\")\n",
    "print(cross_val_score(RBFSVMmodel, X_train, y_train, cv=5))\n",
    "print(\"\\nMean CV Score:\")\n",
    "print(cross_val_score(RBFSVMmodel, X_train, y_train, cv=5).mean()) \n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_predRBF))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_predRBF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLYNOMIAL\n",
    "polynomialSVMmodel=SVC(kernel='poly')\n",
    "polynomialSVMmodel.fit(X_train, y_train)\n",
    "y_predpoly= polynomialSVMmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial SVM Confusion Matrix Results\n",
      "\n",
      "Accuracy Score:\n",
      "0.9777777777777777\n",
      "\n",
      "Cross Validation Score:\n",
      "[0.95238095 0.85714286 0.9047619  1.         0.85      ]\n",
      "\n",
      "Mean CV Score:\n",
      "0.9128571428571428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Polynomial SVM Confusion Matrix Results\")\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test,y_predpoly))\n",
    "print(\"\\nCross Validation Score:\")\n",
    "print(cross_val_score(polynomialSVMmodel, X_train, y_train, cv=5))\n",
    "print(\"\\nMean CV Score:\")\n",
    "print(cross_val_score(polynomialSVMmodel, X_train, y_train, cv=5).mean()) \n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_predpoly))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_predpoly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIGMOID\n",
    "sigmoidSVMmodel=SVC(kernel='sigmoid')\n",
    "sigmoidSVMmodel.fit(X_train, y_train)\n",
    "y_predsigmoid= sigmoidSVMmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid SVM Confusion Matrix Results\n",
      "\n",
      "Accuracy Score:\n",
      "0.8888888888888888\n",
      "\n",
      "Cross Validation Score:\n",
      "[1.         0.9047619  0.85714286 0.95238095 0.85      ]\n",
      "\n",
      "Mean CV Score:\n",
      "0.9128571428571428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0  9  4]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.90      0.69      0.78        13\n",
      "           2       0.75      0.92      0.83        13\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.88      0.87      0.87        45\n",
      "weighted avg       0.90      0.89      0.89        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sigmoid SVM Confusion Matrix Results\")\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test,y_predsigmoid))\n",
    "print(\"\\nCross Validation Score:\")\n",
    "print(cross_val_score(sigmoidSVMmodel, X_train, y_train, cv=5))\n",
    "print(\"\\nMean CV Score:\")\n",
    "print(cross_val_score(sigmoidSVMmodel, X_train, y_train, cv=5).mean()) \n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_predsigmoid))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_predsigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "* **Linear SVM Confusion Matrix Results**\n",
    "    - Accuracy Score: 0.97\n",
    "    - Mean CV Score: 0.9423809523809524\n",
    "\n",
    "* **RBF SVM Confusion Matrix Results**\n",
    "    - Accuracy Score: 1.0\n",
    "    - Mean CV Score: 0.9328571428571429\n",
    "\n",
    "* **Polynomial SVM Confusion Matrix Results**\n",
    "    - Accuracy Score: 0.97\n",
    "    - Mean CV Score: 0.9128571428571428\n",
    "\n",
    "* **Sigmoid SVM Confusion Matrix Results**\n",
    "    - Accuracy Score: 0.88\n",
    "    - Mean CV Score: 0.9128571428571428"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
